{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Shenasa.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i8LXwCrAgPv7"},"source":["*SHENASA FACE ANTI-SPOOFING*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YONM0sJCe07Z","executionInfo":{"status":"ok","timestamp":1632042704296,"user_tz":-120,"elapsed":29092,"user":{"displayName":"erf.mahmood shenasa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13370229187966365073"}},"outputId":"1ea79443-8bea-481f-9c9d-176f6c51ca9a"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","%cd gdrive/MyDrive/shenasa"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"RoP5-Zu2kJ_S"},"source":["import cv2\n","import tensorflow as tf\n","from keras.models import model_from_yaml\n","from keras.models import model_from_json\n","from keras.preprocessing.image import img_to_array\n","from rPPG.rPPG_Extracter import *\n","from rPPG.rPPG_lukas_Extracter import *\n","import os\n","import shutil\n","import keras\n","import time\n","import numpy as np\n","from shutil import copyfileme\n","from progressbar import ProgressBar\n","from tensorflow.keras.callbacks import EarlyStopping\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YZ6NECdksmp"},"source":["def frames_(video_name):\n","  \"\"\"\n","  this function gets all the frames of a video (used for train dataset)\n","  the output frames will be in train/1/image/{name}\n","\n","\n","  parameters:\n","    video_name: name of the video that will be processed \n","\n","  return:\n","    None\n","\n","  \"\"\"\n","  # Opens the Video file\n","  name = video_name.split('.')[0]\n","  cap= cv2.VideoCapture(f'train/1/{video_name}')\n","  if not os.path.isdir(f\"train/1/image/{name}\"):\n","    os.mkdir(f\"train/1/image/{name}\")\n","  i=0\n","  # print(cap.isOpened())\n","  while(cap.isOpened()):\n","      ret, frame = cap.read()\n","      if ret == False:\n","          break\n","      cv2.imwrite(f'train/1/image/{name}/'+str(i)+'.jpg',frame)\n","      i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJZTct_f5X4i"},"source":["def frames_D(video_name):\n","  \"\"\"\n","  this function gets all the frames of a video (used for test dataset)\n","  the output frames will be in test/1/image/{name}\n","\n","  parameters:\n","    video_name: name of the video that will be processed \n","\n","  return:\n","    None\n","\n","  \"\"\"\n","  # Opens the Video file\n","  name = video_name.split('.')[0]\n","  cap= cv2.VideoCapture(f'test/1/{video_name}')\n","  if not os.path.isdir(f\"test/1/image/{name}\"):\n","    os.mkdir(f\"test/1/image/{name}\")\n","  i=0\n","  # print(cap.isOpened())\n","  while(cap.isOpened()):\n","      ret, frame = cap.read()\n","      if ret == False:\n","          break\n","      cv2.imwrite(f'test/1/image/{name}/'+str(i)+'.jpg',frame)\n","      i+=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GA1xFuay6J6z"},"source":["def eval_frames(): \n","  \"\"\"\n","  this function select some frames from a frame file, add the face cordinations\n","   and name of the video as the name of the file and save it in test/frane for\n","   further processes\n","\n","  parameters:\n","    None \n","\n","  return:\n","    None\n","  \"\"\" \n","  ma_films = os.listdir(f'test/1')\n","  for j, i in enumerate(ma_films):\n","    if 'avi' in i:\n","\n","      name = i.split('.')[0]\n","      print(name)\n","\n","      ma_text = name + '.txt'\n","\n","      with open('test/1/'+ma_text) as f:\n","        lines = f.readlines()\n","      ma_face = [line[:-1] for line in lines]\n","\n","      frames_D(i)\n","\n","      ma_len = len(os.listdir(f\"test/1/image/{name}/\"))\n","      \n","      \n","      for counter in range(0,ma_len,ma_len//5):\n","        face = list(map(int, ma_face[counter].split(',')))[1:]\n","        name1 = ','.join(map(str,face))\n","        copyfile(f\"test/1/image/{name}/{counter}.jpg\", f\"test/frame/{name}+{counter}+{name1}.jpg\")\n","      \n","      shutil.rmtree(f\"test/1/image/{name}/\")\n","      print(j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPPaIF3zwfz8"},"source":["dim = (128,128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjb2-zQGuLCm"},"source":["def get_rppg_pred(frame):\n","    \"\"\"\n","    this function is used to return the rppg predictions of images\n","\n","    parameters:\n","      the specific frame\n","\n","    return:\n","      the rppg predictaion\n","    \"\"\"\n","    use_classifier = True  \n","                                 \n","    sub_roi = []           \n","    use_resampling = False  \n","    \n","    fs = 20\n","\n","    timestamps = []\n","    time_start = [0]\n","\n","    break_ = False\n","\n","    rPPG_extracter = rPPG_Extracter()\n","    rPPG_Lukas_Extracter()\n","    bpm = 0\n","    \n","    dt = time.time()-time_start[0]\n","    time_start[0] = time.time()\n","    if len(timestamps) == 0:\n","        timestamps.append(0)\n","    else:\n","        timestamps.append(timestamps[-1] + dt)\n","        \n","\n","    rPPG_extracter.measure_rPPG(frame,use_classifier,sub_roi) \n","    rPPG = np.transpose(rPPG_extracter.rPPG)\n","    \n","        # Extract Pulse\n","    if rPPG.shape[1] > 10:\n","        if use_resampling :\n","            t = np.arange(0,timestamps[-1],1/fs)\n","            \n","            rPPG_resampled= np.zeros((3,t.shape[0]))\n","            for col in [0,1,2]:\n","                rPPG_resampled[col] = np.interp(t,timestamps,rPPG[col])\n","            rPPG = rPPG_resampled\n","        num_frames = rPPG.shape[1]\n","\n","    return rPPG"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cpPSZqiTnUs0"},"source":["def make_pred(li):\n","    \"\"\"\n","    this function predict a single image recording to its rppg prediction and the image itself\n","\n","    parameters:\n","      list: a list with first element the image and second the rppg prediction\n","\n","    return \n","      prediction that shows if the image is an attack or if it is not\n","    \"\"\"\n","    [single_img,rppg] = li\n","    print(single_img.shape)\n","    single_img = cv2.resize(single_img, dim)\n","    single_x = img_to_array(single_img)\n","    single_x = np.expand_dims(single_x, axis=0)\n","\n","    print(single_img.shape)\n","    print('============')\n","    print(single_x.shape)\n","    print('============')\n","    print(rppg.shape)\n","\n","    single_pred = model.predict([single_x,rppg])\n","    return single_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUDOzxrEYq0J"},"source":["def images_pred(name):\n","  \"\"\"\n","  this function predict frames of a specific video\n","\n","  parameters:\n","    name: video name without .avi\n","  \n","  return:\n","    list of predictions\n","  \"\"\"\n","\n","  f_name = name+'.avi'\n","  ma_pred = []\n","  frames_(f_name)\n","  ma_face = np.loadtxt(f\"train/1/{name}.txt\", dtype=str)\n","  for counter, i in enumerate(os.listdir(f'train/1/image/{name}/')):\n","    im = cv2.imread(f\"train/1/image/{name}/{i}\")\n","    face = list(map(int, ma_face[counter].split(',')))[1:]\n","\n","    x, y, w, h = face\n","    sub_img=im[y:y+h,x:x+w]\n","    \n","    rppg_s = get_rppg_pred(sub_img)\n","    rppg_s = rppg_s.T\n","    pred = make_pred([sub_img,rppg_s])\n","    ma_pred.append(pred)\n","  return ma_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QUVhDRosFZwg"},"source":["def images_evaluate(model, path):\n","  \"\"\"\n","  this function is used to evaluate some images in a specific directory\n","\n","  parameters:\n","    model: the model that is used to predict images\n","    path: the directory in which the images are\n","\n","  return:\n","    evaluation scores of the images\n","  \"\"\"\n","  ma_frames = os.listdir(f'dev/{path}')\n","\n","  list_labels = []\n","  ma_sub_imgs = []\n","  ma_rppg_ss = []\n","\n","  for index, i in enumerate(ma_frames):\n","    label, counter, faces = i.split('+')\n","    faces = faces.split('.')[0]\n","    \n","    faces = list(map(int, faces.split(',')))\n","    im = cv2.imread(f\"dev/{path}/{i}\")\n","\n","    label = label[-1]=='1'\n","    if label:\n","      list_labels.append([1,0])\n","    else:\n","      list_labels.append([0,1])\n","\n","    x,y,w,h = faces\n","    sub_img = im[y:y+h,x:x+w]\n","    rppg_s = get_rppg_pred(sub_img)\n","    rppg_s = rppg_s.T\n","\n","    sub_img = cv2.resize(sub_img, dim)\n","    sub_img = img_to_array(sub_img)\n","    sub_img = np.expand_dims(sub_img, axis=0)\n","\n","    sub_img = sub_img.reshape(128,128,3)\n","    rppg_s = rppg_s.reshape(3)\n","\n","    ma_sub_imgs.append(sub_img)\n","    ma_rppg_ss.append(rppg_s)\n","\n","    print(index)\n","\n","  return model.evaluate(x=[np.array(ma_sub_imgs), np.array(ma_rppg_ss)], y=np.array(list_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDEWdh-nlwEB"},"source":["# this script is used to delete files and folders from the trash of google drive\n","\n","def login():\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  my_drive = GoogleDrive(gauth)\n","  return my_drive\n","login()\n","\n","# delete folder\n","def delte_from_trash():\n","  my_drive = login()\n","  while True:\n","    try:\n","      path = my_drive.ListFile({'q': \"trashed = true\"}).GetList()\n","      if len(path) == 0 : break\n","      for a_file in my_drive.ListFile({'q': \"trashed = true\"}).GetList():\n","        a_file.Delete()\n","    except:\n","      my_drive = login()\n","delte_from_trash()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVjzzkSeeJo6"},"source":["def get_generator():\n","  \"\"\"\n","  this is the main generator that is used to train the model\n","  the files in train/1 are used to train the model\n","\n","  in each step it yields frames of a video\n","  \"\"\"\n","\n","  while True:\n","    ma_films = os.listdir(f'train/1')\n","    count = 0\n","    for i in ma_films:\n","      \n","      if count == 300:\n","        break\n","\n","      if 'avi' in i:\n","       \n","        name = i.split('.')[0]\n","\n","        # change this line if you want to use more or less frames\n","        number_frame = 30\n","\n","        # this part can be modified according to your segmentation of real and\n","        # attack images... \n","        # if you want to use every single file, delete these 2 lines\n","        if name[-1] in ['3','5']:\n","          continue\n","\n","        print('filme:',name)\n","\n","        count+=1\n","        print('   counter: ',count)\n","\n","        ma_text = name + '.txt'\n","        with open('train/1/'+ma_text) as f:\n","          lines = f.readlines()\n","        ma_face = [line[:-1] for line in lines]\n","\n","        frames_(i)\n","        \n","        list_images_array = []\n","        list_face_array = []\n","\n","        ma_len = len(os.listdir(f\"train/1/image/{name}/\"))\n","\n","        for counter in range(0,ma_len,ma_len//number_frame):\n","\n","          im = cv2.imread(f\"train/1/image/{name}/{counter}\"+'.jpg')\n","          face = list(map(int, ma_face[counter].split(',')))[1:]\n","          flag = True\n","          if face == [0,0,0,0]:\n","            flag = False\n","            count -= 1\n","            break\n","\n","          list_images_array.append(im)\n","          list_face_array.append(face)\n","\n","        if flag == False:\n","          continue\n","          \n","\n","        ma_sub_imgs = []\n","        ma_rppg_ss = []\n","\n","        ma_sub_imgs = []\n","        ma_rppg_ss = []\n","        for j in range(len(list_images_array)):\n","          try:\n","\n","            x, y, w, h = list_face_array[j]\n","            sub_img = list_images_array[j][y:y+h,x:x+w]\n","\n","            rppg_s = get_rppg_pred(sub_img)\n","            rppg_s = rppg_s.T\n","\n","\n","            sub_img = cv2.resize(sub_img, dim)\n","            sub_img = img_to_array(sub_img)\n","            sub_img = np.expand_dims(sub_img, axis=0)\n","\n","            sub_img = sub_img.reshape(128,128,3)\n","            rppg_s = rppg_s.reshape(3)\n","\n","            ma_sub_imgs.append(sub_img)\n","\n","            ma_rppg_ss.append(rppg_s)\n","          except:\n","            print()\n","            print(f\"could not procces image number {j}\")\n","            print()\n","\n","        labels = []\n","        if '1' in name[-1]:\n","          labels.append([1,0])\n","          labels*=len(list_images_array)\n","        else:\n","          labels.append([0,1])\n","          labels*=len(list_images_array)\n","        print()\n","        print(f'  deleting file {name}')\n","        shutil.rmtree(f\"train/1/image/{name}/\")\n","\n","        delte_from_trash()\n","\n","        yield ([np.array(ma_sub_imgs), np.array(ma_rppg_ss)], np.array(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VG-55Z8WW5s5"},"source":["ma_generator = get_generator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLTZuiy_JDcY"},"source":["def prediction_test():\n","  \"\"\"\n","  this function simply returns prediction of frames in the test/frame directory\n","  \"\"\"\n","  result = []\n","  ma_frames = os.listdir(f'test/frame')\n","  counter = 0\n","  for i in ma_frames:\n","    print('*'*20)\n","    print(counter)\n","    print('*'*20)\n","    im = cv2.imread(f'test/frame/{i}')\n","    face = list(map(int, i.split('+')[2].split('.')[0].split(',')))\n","\n","    x, y, w, h = face\n","    sub_img=im[y:y+h,x:x+w]\n","    \n","    rppg_s = get_rppg_pred(sub_img)\n","    rppg_s = rppg_s.T\n","    pred = make_pred([sub_img,rppg_s])\n","    result.append(pred)\n","    counter += 1\n","  result = np.array(result).reshape(3600, -1) \n","  return tf.math.argmin(result, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMmMqcbbHzbT"},"source":["def labels_test():\n","  \"\"\"\n","  this function simply returns labels of frames in test/frame directory\n","  \"\"\"\n","  result = []\n","  ma_frames = os.listdir(f'test/frame')\n","  for i in ma_frames:\n","    result.append(i.split('+')[0][-1])\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a39ElNdK9uS"},"source":["# this script is used to check out the confusion matrix \n","p1 = prediction_test()\n","l1 = labels_test()\n","res = tf.math.confusion_matrix(tf.convert_to_tensor(list(map(int,l1))), p1)\n","print(res)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3VlISHunbSc"},"source":["# loading the model\n","json_file = open('RGB_rPPG_merge_softmax_.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","model = model_from_json(loaded_model_json)\n","model.load_weights(\"test_30_180_1.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8Orxh5bs4Gj"},"source":["# compiling the model :D\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXjddt_JXX5D"},"source":["%%time\n","history = model.fit_generator(ma_generator, steps_per_epoch=180, epochs=1, verbose=1, callbacks=[ma_callbask])\n","# frame - film number - trained epoch \n","model.save_weights(\"test_30_180_3.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaMAa1SpJ8gZ"},"source":["def evaluate_score(model, path):\n","  # this function just evaluate and prints the evaluation scores of images in specific path.\n","  score = images_evaluate(model, path)\n","  print(path)\n","  print('Test loss:', score[0]) \n","  print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFGy-sroZi7p"},"source":["evaluate_score(model, 'real')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_c3fTRIyh3uE"},"source":["evaluate_score(model, 'replay')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NzMdNGKh3pL"},"source":["evaluate_score(model, 'print')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mj3j0prWVIdV"},"source":["evaluate_score(model, 'frame')"],"execution_count":null,"outputs":[]}]}
