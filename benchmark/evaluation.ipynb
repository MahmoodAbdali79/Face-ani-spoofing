{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5xAhi0jRQXQp52x+jU6UR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahmoodAbdali79/Face-ani-spoofing/blob/main/benchmark/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Aeyi_qDF-H9"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from rPPG.rPPG_Extracter import *\n",
        "from rPPG.rPPG_lukas_Extracter import *\n",
        "from keras.models import model_from_json\n",
        "import tensorflow as tf\n",
        "from random import seed\n",
        "# from random import randint\n",
        "from random import sample\n",
        "\n",
        "seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLH6MhwxX4pt"
      },
      "source": [
        "dim = (128,128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcsNnxhQiSeD"
      },
      "source": [
        "cascPath = './cv2_model/haarcascade_frontalface_default.xml'\n",
        "faceCascade = cv2.CascadeClassifier(cascPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX13dfECE8gl"
      },
      "source": [
        "def extract_frames(path):\n",
        "  \"\"\"\n",
        "  extract frames from videos (each 5 frames) with this order: numberfolder_filemname_x,y,w,h_label.jpg\n",
        "\n",
        "  parameters:\n",
        "    path : main folder of videos\n",
        "\n",
        "  retuen:\n",
        "    just save given frame\n",
        "  \"\"\"\n",
        "  folders = os.listdir(path)\n",
        "  os.mkdir(f\"{path}/frames\")\n",
        "  \n",
        "  for folder in folders:\n",
        "    print(f'exracting foder {folder} ...')\n",
        "    videos = os.listdir(f'{path}/{folder}')\n",
        "    for video in videos:\n",
        "      print(video.split('.')[0], ' ...')\n",
        "      name = video.split('.')[0]\n",
        "      if name in ['1','2','HR_1'] : label = '1'\n",
        "      else : label = '0'\n",
        "      cap = cv2.VideoCapture(f'{path}/{folder}/{video}')\n",
        "      \n",
        "      try:\n",
        "        i = 0 \n",
        "        counter = 0\n",
        "        while True:\n",
        "          ret, frame = cap.read()\n",
        "          if not ret: break\n",
        "          i += 1\n",
        "          # detect face \n",
        "          gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "          faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "          if i%5 == 0 and len(faces) != 0:\n",
        "            x, y, w, h = faces[0]\n",
        "            print( faces[0],len(faces[0]) , f'counter: {counter+1}')\n",
        "            cv2.imwrite(f'{path}/frames/{folder}_{name}_{x},{y},{w},{h}_{label}.jpg', frame)\n",
        "            counter += 1\n",
        "      finally:\n",
        "        cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDoK5AGrGKyq"
      },
      "source": [
        "extract_frames('test_release')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUdPcvUxWPaP"
      },
      "source": [
        "def get_rppg_pred(frame):\n",
        "    use_classifier = True  \n",
        "                                 \n",
        "    sub_roi = []           \n",
        "    use_resampling = False  \n",
        "    \n",
        "    fs = 20\n",
        "\n",
        "    timestamps = []\n",
        "    time_start = [0]\n",
        "\n",
        "    break_ = False\n",
        "\n",
        "    rPPG_extracter = rPPG_Extracter()\n",
        "    rPPG_Lukas_Extracter()\n",
        "    bpm = 0\n",
        "    \n",
        "    dt = time.time()-time_start[0]\n",
        "    time_start[0] = time.time()\n",
        "    if len(timestamps) == 0:\n",
        "        timestamps.append(0)\n",
        "    else:\n",
        "        timestamps.append(timestamps[-1] + dt)\n",
        "        \n",
        "\n",
        "    rPPG_extracter.measure_rPPG(frame,use_classifier,sub_roi) \n",
        "    rPPG = np.transpose(rPPG_extracter.rPPG)\n",
        "    \n",
        "        # Extract Pulse\n",
        "    if rPPG.shape[1] > 10:\n",
        "        if use_resampling :\n",
        "            t = np.arange(0,timestamps[-1],1/fs)\n",
        "            \n",
        "            rPPG_resampled= np.zeros((3,t.shape[0]))\n",
        "            for col in [0,1,2]:\n",
        "                rPPG_resampled[col] = np.interp(t,timestamps,rPPG[col])\n",
        "            rPPG = rPPG_resampled\n",
        "        num_frames = rPPG.shape[1]\n",
        "\n",
        "        \n",
        "    return rPPG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_TOj559WPX4"
      },
      "source": [
        "def make_pred(li):\n",
        "    [single_img,rppg] = li\n",
        "    single_img = cv2.resize(single_img, dim)\n",
        "    single_x = img_to_array(single_img)\n",
        "    single_x = np.expand_dims(single_x, axis=0)\n",
        "    single_pred = model.predict([single_x,rppg])\n",
        "    return single_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09QH776_WPEf"
      },
      "source": [
        "def prediction_test(path):\n",
        "   \"\"\"\n",
        "  predict all extracted frames from videos in  folder test_release/frames\n",
        "\n",
        "  paramter:\n",
        "    path : main folder of videos\n",
        "\n",
        "  return:\n",
        "    result: predicted classes for all frames\n",
        "    label: real classes of all frames\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  label = []\n",
        "  ma_frames = os.listdir(f'{path}/frames')\n",
        "  counter = 0\n",
        "\n",
        "  for i in ma_frames:\n",
        "    print(f'{counter}:', i)\n",
        "    im = cv2.imread(f'{path}/frames/{i}')\n",
        "    if 'HR' in i:\n",
        "      face = list(map(int, i.split('_')[3].split(',')))\n",
        "    else:\n",
        "      face = list(map(int, i.split('_')[2].split(',')))\n",
        "\n",
        "    x, y, w, h = face\n",
        "    sub_img=im[y:y+h,x:x+w]\n",
        "    \n",
        "    rppg_s = get_rppg_pred(sub_img)\n",
        "    rppg_s = rppg_s.T\n",
        "    # print(sub_img.shape)\n",
        "    # print(rppg_s)\n",
        "    pred = make_pred([sub_img,rppg_s])\n",
        "    result.append(pred)\n",
        "    label.append(int(i.split('_')[-1].split('.')[0]))\n",
        "    counter += 1\n",
        "\n",
        "  result = np.array(result).reshape(len(result), -1) \n",
        "  result = tf.math.argmin(result, axis=1)\n",
        "  label = tf.convert_to_tensor(label)\n",
        "  \n",
        "  return result, label\n",
        "  \n",
        "\n",
        "\n",
        "def PredictSepratedClass(class_folder):\n",
        "  \"\"\"\n",
        "  predict frames from eache class that seprated to each other in benchmark_type folder\n",
        "\n",
        "  paramter:\n",
        "    class_folder : single class folder\n",
        "\n",
        "  return:\n",
        "    result: predicted classes for all frames\n",
        "    label: real classes of all frames\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  label = []\n",
        "  frames = os.listdir('benchmark_type/'+class_folder)\n",
        "\n",
        "  for i, frame in enumerate(frames):\n",
        "    print(f'Counter {i} ... ')\n",
        "    img = cv2.imread(f'benchmark_type/{class_folder}/{frame}')\n",
        "    if 'HR' in frame:\n",
        "      x, y, w, h = list(map(int,frame.split('_')[3].split(',')))\n",
        "    else:\n",
        "      x, y, w, h = list(map(int,frame.split('_')[2].split(',')))\n",
        "    sub_img = img[y:y+h,x:x+w]\n",
        "\n",
        "    rppg_s = get_rppg_pred(sub_img)\n",
        "    rppg_s = rppg_s.T\n",
        "    pred = make_pred([sub_img,rppg_s])\n",
        "    result.append(pred)\n",
        "    label.append(int(frame.split('_')[-2]))\n",
        "\n",
        "  result = np.array(result).reshape(len(result), -1) \n",
        "  result = tf.math.argmin(result, axis=1)\n",
        "  label = tf.convert_to_tensor(label)\n",
        "\n",
        "  return result, label\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MCm5phKf452"
      },
      "source": [
        "# load model\n",
        "json_file = open('../RGB_rPPG_merge_softmax_.json', 'r')  \n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "\n",
        "#load weights and compile\n",
        "model.load_weights(\"../RGB_rPPG_merge_softmax_.h5\")\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjjRXKvHXylb"
      },
      "source": [
        "result, label = prediction_test('test_release')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGKOK1k-fXDK"
      },
      "source": [
        "#showing confusion matrix of predicts\n",
        "res = tf.math.confusion_matrix(label,result)\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ITYwJI9lhe"
      },
      "source": [
        "# extracte frame from videos and save them in seprated folder bases on classes\n",
        "def extract_frame(video_paht):  \n",
        "  folder = video_paht.split('/')[1] \n",
        "  name = video_paht.split('.')[0].split('/')[-1]\n",
        "  label = '0'\n",
        "  number_frame = 10\n",
        "  out_folder = '' \n",
        "\n",
        "  if name in ['1','2','HR_1'] : \n",
        "    label = '1'\n",
        "    number_frame = 30\n",
        "    out_folder = 'real'\n",
        "  elif name in ['3', '4', 'HR_2']:\n",
        "    out_folder = 'print'\n",
        "  elif name in ['7', '8', 'HR_4']:\n",
        "    out_folder = 'reply'\n",
        "  elif name in ['5', '6', 'HR_3']:\n",
        "    out_folder = 'print_eye'\n",
        "\n",
        "  print(f'    Extracting {name}.avi ...')\n",
        "\n",
        "  cap = cv2.VideoCapture(video_paht)\n",
        "  length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  selected_frame = np.sort(sample(range(length), number_frame))\n",
        "  last_frame = selected_frame[-1]\n",
        "\n",
        "  A = []\n",
        "\n",
        "  try:\n",
        "    i = 0 \n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret: break\n",
        "\n",
        "      # detect face\n",
        "      try:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "        if i in selected_frame and len(faces) != 0:\n",
        "          A.append(i)\n",
        "          # print(f'in frame : {i}')\n",
        "          x, y, w, h = faces[0]\n",
        "          cv2.imwrite(f'benchmark_type/{out_folder}/{folder}_{name}_{x},{y},{w},{h}_{label}_{i}.jpg', frame)\n",
        "      \n",
        "        i += 1\n",
        "      except Exception as e:\n",
        "        print(f'can not write frame {i}')\n",
        "        print(e)\n",
        "      if i == last_frame+1:\n",
        "        break\n",
        "\n",
        "  finally:\n",
        "    cap.release()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X59y-DT9n1-"
      },
      "source": [
        "# sending vode_path to extract_frame function\n",
        "def ExtractFrameBasedOnClass(path):\n",
        "  folders = os.listdir(path)\n",
        "  \n",
        "  for folder in folders:\n",
        "    print(f'On folder {folder} ...')\n",
        "    videos = os.listdir(f'{path}/{folder}')\n",
        "    for video in videos:\n",
        "      extract_frame(f'{path}/{folder}/{video}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd3IcvXONTXy"
      },
      "source": [
        "ExtractFrameBasedOnClass('test_release')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17R5TxS9nxP"
      },
      "source": [
        "result, label = PredictSepratedClass('reply')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Xw7Kd8i-D-"
      },
      "source": [
        "res = tf.math.confusion_matrix(label,result)\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-DrNZYYvBv"
      },
      "source": [
        "# Separation of high rezolution from low rezolution\n",
        "\n",
        "def seprate_HR():\n",
        "  folders = os.listdir('test_release')\n",
        "  for folder in folders:\n",
        "    files = os.listdir(f'test_release/{folder}')\n",
        "    for file_name in files:\n",
        "\n",
        "      sub_folder = 'NOHR'\n",
        "      if file_name in ['HR_1.avi', 'HR_2.avi', 'HR_4.avi', 'HR_3.avi']:\n",
        "        sub_folder = 'HR'\n",
        "\n",
        "      label = '0'\n",
        "      number_frame = 16\n",
        "      if file_name in ['1.avi', '2.avi', 'HR_1.avi']:\n",
        "        label = '1'\n",
        "        number_frame = 31\n",
        "\n",
        "      cap = cv2.VideoCapture(f'test_release/{folder}/{file_name}')\n",
        "      frames = []\n",
        "      faces = []\n",
        "      i = 1 \n",
        "\n",
        "      while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        i+=1\n",
        "        try:\n",
        "          gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "          face = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "          if len(face) != 0:\n",
        "            faces.append(face[0])\n",
        "            frames.append(frame)\n",
        "        except Exception as e:\n",
        "          print(f'can not write frame {i}')\n",
        "          print(e)\n",
        "      \n",
        "      faces = np.array(faces)\n",
        "      frames = np.array(frames)\n",
        "\n",
        "      length = faces.shape[0]\n",
        "      if length<2:\n",
        "        continue\n",
        "\n",
        "      selected_frame = np.sort(sample(range(1, length), min(length, number_frame)-1))\n",
        "      selected_faces = faces[selected_frame]\n",
        "      selected_frames = frames[selected_frame]\n",
        "\n",
        "      for i, f in enumerate(selected_frames):\n",
        "        x, y, w, h = faces[i]\n",
        "        cv2.imwrite(f'HR_NOHR/{sub_folder}/{folder}_{file_name.split(\".\")[0]}_{x},{y},{w},{h}_n{i}_{label}.jpg', f)    # add countre \n",
        "        print(f'  {folder}_{file_name.split(\".\")[0]}_{x},{y},{w},{h}_n{i}_{label}.jpg')\n",
        "      \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghJtLWafjclJ"
      },
      "source": [
        "seprate_HR()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz_3IxYn1lV1"
      },
      "source": [
        "def prediction_HRNOHR_test(path):  \n",
        "    \"\"\"\n",
        "  predict frames seprated in HR/NOHR folder based on High-rezolution/Low-rezolution\n",
        "\n",
        "  paramter:\n",
        "    class_folder : single class folder\n",
        "\n",
        "  return:\n",
        "    result: predicted classes for all frames\n",
        "    label: real classes of all frames\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  label = []\n",
        "  ma_frames = os.listdir(f'{path}')\n",
        "  counter = 1\n",
        "  for i in ma_frames:\n",
        "    print(f'{counter}:', i)\n",
        "    im = cv2.imread(f'{path}/{i}')\n",
        "    if 'HR' in i:\n",
        "      face = list(map(int, i.split('_')[3].split(',')))\n",
        "    else:\n",
        "      face = list(map(int, i.split('_')[2].split(',')))\n",
        "\n",
        "    x, y, w, h = face\n",
        "    sub_img = im[y:y+h,x:x+w]\n",
        "    \n",
        "    rppg_s = get_rppg_pred(sub_img)\n",
        "    rppg_s = rppg_s.T\n",
        "    # print(sub_img.shape)\n",
        "    # print(rppg_s)\n",
        "    pred = make_pred([sub_img,rppg_s])\n",
        "    result.append(pred)\n",
        "    label.append(int(i.split('_')[-1].split('.')[0]))\n",
        "    counter += 1\n",
        "\n",
        "  result = np.array(result).reshape(len(result), -1) \n",
        "  result = tf.math.argmin(result, axis=1)\n",
        "  label = tf.convert_to_tensor(label)\n",
        "\n",
        "  return result, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UScb0Lf53VXQ"
      },
      "source": [
        "result, label = prediction_HRNOHR_test('HR_NOHR/HR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCVrqrDd3cQD"
      },
      "source": [
        "res = tf.math.confusion_matrix(label,result)\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}